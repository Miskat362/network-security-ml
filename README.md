# ğŸ›¡ï¸ Network Security: ML-Powered Phishing Detection System

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-green?style=for-the-badge&logo=fastapi)
![MongoDB](https://img.shields.io/badge/MongoDB-Latest-green?style=for-the-badge&logo=mongodb)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue?style=for-the-badge&logo=mlflow)

**An Enterprise-Grade End-to-End ML Pipeline for Real-Time Phishing Detection**

</div>

---

## ğŸ“‹ Overview

**Network Security** is a production-ready machine learning system that detects and prevents phishing attacks through intelligent network data analysis. Built with a focus on scalability, reliability, and performance, this project implements a complete MLOps pipeline using industry-standard tools and best practices.

The system processes raw network data through automated ingestion, validation, transformation, and model training stages, then serves real-time predictions via a high-performance FastAPI service integrated with MLflow for experiment tracking and DagsHub for model versioning.

---

## âœ¨ Key Features

- ğŸ”„ **Automated Data Ingestion Pipeline** - Seamlessly loads phishing network data from CSV into MongoDB
- âœ… **Robust Data Validation** - Schema validation with comprehensive error handling
- ğŸ”§ **Intelligent Data Transformation** - Feature engineering and preprocessing optimized for ML models
- ğŸ¤– **Advanced Model Training** - Multiple ensemble algorithms (Random Forest, Gradient Boosting, AdaBoost, Logistic Regression)
- âš¡ **Real-Time Prediction API** - FastAPI service for instant phishing detection on new data
- ğŸ“Š **MLOps Integration** - MLflow tracking + DagsHub versioning for reproducible experiments
- ğŸ³ **Docker Ready** - Containerized deployment for seamless cloud integration
- ğŸ“ˆ **Performance Monitoring** - Classification metrics and model evaluation
- ğŸ” **Production-Grade** - Exception handling, logging, and error management throughout

---

## ğŸ—ï¸ Architecture

```
Network Security ML Pipeline
â”œâ”€â”€ ğŸ“¥ Data Ingestion (CSV â†’ MongoDB)
â”œâ”€â”€ âœ”ï¸ Data Validation (Schema Check)
â”œâ”€â”€ ğŸ”„ Data Transformation (Feature Engineering)
â”œâ”€â”€ ğŸ¯ Model Training (Ensemble Methods)
â””â”€â”€ ğŸš€ Prediction Service (FastAPI REST API)
```

**Tech Stack:**
- **Data Processing:** Pandas, NumPy, Scikit-learn
- **ML Frameworks:** Scikit-learn, MLflow, DagsHub
- **Backend:** FastAPI, Uvicorn
- **Database:** MongoDB
- **MLOps:** MLflow, DagsHub
- **Environment:** Python 3.9+

---

## ğŸš€ Installation

### Prerequisites

Ensure you have the following installed:

- **Python 3.9+** - [Download Python](https://www.python.org/)
- **MongoDB** - [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) (Cloud) or [Local Installation](https://www.mongodb.com/docs/manual/installation/)
- **Git** - Version control system
- **pip** - Python package manager

### Step-by-Step Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/Miskat362/network-security-ml.git
   cd network-security-ml
   ```

2. **Create Virtual Environment**
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure Environment Variables**
   Create a `.env` file in the root directory:
   ```env
   MONGODB_URL_KEY=mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority
   ```

5. **Verify Installation**
   ```bash
   python -c "import network_security; print('Installation successful!')"
   ```

---

## ğŸ’¡ Quick Start

### 1. Train the Model

**Using the Training Pipeline:**
```bash
python main.py
```

**Using the FastAPI Endpoint:**
```bash
# Start the server
uvicorn app:app --reload

# In another terminal, trigger training
curl http://localhost:8000/train
```

### 2. Make Predictions

**Using the REST API:**
```bash
# Start the FastAPI server
uvicorn app:app --reload

# Make a prediction request
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @sample_data.json
```

### 3. Monitor Experiments

Open MLflow UI to track model experiments:
```bash
mlflow ui
```
Visit `http://localhost:5000` in your browser.

### 4. View API Documentation

Start the server and navigate to:
- **Swagger UI:** `http://localhost:8000/docs`
- **ReDoc:** `http://localhost:8000/redoc`

---

## ğŸ“ Project Structure

```
network-security-ml/
â”œâ”€â”€ ğŸ“„ app.py                          # FastAPI application entry point
â”œâ”€â”€ ğŸ“„ main.py                         # Training pipeline execution script
â”œâ”€â”€ ğŸ“„ setup.py                        # Package setup configuration
â”œâ”€â”€ ğŸ“„ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile                      # Docker container configuration
â”œâ”€â”€ ğŸ“„ README.md                       # This file
â”‚
â”œâ”€â”€ ğŸ” network_security/               # Main package directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ“ components/                 # ML pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py         # MongoDB data loading
â”‚   â”‚   â”œâ”€â”€ data_validation.py        # Schema & data quality validation
â”‚   â”‚   â”œâ”€â”€ data_transformation.py    # Feature engineering & preprocessing
â”‚   â”‚   â””â”€â”€ model_trainer.py          # Model training & evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ pipeline/                   # Orchestration
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py      # End-to-end training workflow
â”‚   â”‚   â””â”€â”€ batch_prediction.py       # Batch prediction module
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ entity/                     # Data structure definitions
â”‚   â”‚   â”œâ”€â”€ config_entity.py          # Configuration classes
â”‚   â”‚   â””â”€â”€ artifact_entity.py        # Artifact classes
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ exception/                  # Error handling
â”‚   â”‚   â””â”€â”€ exception.py              # Custom exceptions
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ logging/                    # Logging configuration
â”‚   â”‚   â””â”€â”€ logger.py                 # Custom logger setup
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ constant/                   # Constants & configurations
â”‚   â”‚   â””â”€â”€ training_pipeline/        # Pipeline-specific constants
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/                      # Utility functions
â”‚   â”‚   â”œâ”€â”€ main_utils/
â”‚   â”‚   â”‚   â””â”€â”€ utils.py              # General utilities
â”‚   â”‚   â””â”€â”€ ml_utils/
â”‚   â”‚       â”œâ”€â”€ model/
â”‚   â”‚       â”‚   â””â”€â”€ estimator.py      # Model wrapper
â”‚   â”‚       â””â”€â”€ metric/
â”‚   â”‚           â””â”€â”€ classification_metric.py  # Evaluation metrics
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ cloud/                      # Cloud integration (future)
â”‚
â”œâ”€â”€ ğŸ“Š data_schema/
â”‚   â””â”€â”€ schema.yaml                    # Data schema definition
â”‚
â”œâ”€â”€ ğŸ“‚ network_data/
â”‚   â””â”€â”€ phishingData.csv              # Source phishing dataset
â”‚
â”œâ”€â”€ ğŸ“‚ Artifacts/                      # Generated models & artifacts
â”‚   â””â”€â”€ {timestamp}/
â”‚       â”œâ”€â”€ data_ingestion/
â”‚       â”œâ”€â”€ data_validation/
â”‚       â”œâ”€â”€ data_transformation/
â”‚       â””â”€â”€ model_trainer/
â”‚
â”œâ”€â”€ ğŸ“‚ final_model/                    # Final trained model storage
â”‚
â””â”€â”€ ğŸ“‚ logs/                           # Application logs
```

---

## ğŸ”„ Pipeline Workflow

The system follows a well-defined ML pipeline with the following stages:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data   â”‚ (CSV files in network_data/)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Ingestion      â”‚ Loads data from CSV â†’ MongoDB
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Validation     â”‚ Validates schema & data quality
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Transformation â”‚ Feature engineering & preprocessing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training      â”‚ Trains ensemble models, logs with MLflow
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction Service  â”‚ REST API for real-time inference
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root:

```env
# MongoDB Connection
MONGODB_URL_KEY=mongodb+srv://user:password@cluster.mongodb.net/

# MLflow & DagsHub (Optional)
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=network-security-phishing-detection
```

### Data Schema

Define your data validation schema in `data_schema/schema.yaml`:

```yaml
name: phishing_data
version: 1.0
columns:
  - feature_name: string
  - feature_value: float
required: true
```

---

## ğŸ“Š Supported Models

The project supports multiple ensemble and classical algorithms:

- **Random Forest Classifier** - Robust ensemble method
- **Gradient Boosting Classifier** - Advanced boosting technique
- **AdaBoost Classifier** - Adaptive boosting
- **Logistic Regression** - Linear baseline model

Model selection and hyperparameter tuning are handled automatically during training.

---

## ğŸ³ Docker Deployment

Build and run the application in a Docker container

---

## ğŸ“ˆ Model Performance

The trained models are evaluated using comprehensive classification metrics:

- **Accuracy** - Overall correctness
- **Precision** - True positive rate among predictions
- **Recall** - True positive rate among actual positives
- **F1-Score** - Harmonic mean of precision and recall
- **ROC-AUC** - Area under the receiver operating characteristic curve

All metrics are logged in MLflow for experiment tracking.

---
### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt

```
---

## ğŸ‘¨â€ğŸ’» Author

**Miskat Ahmmed**
- ğŸ“§ Email: memiskat362@gmail.com
- ğŸ”— GitHub: [@Miskat362](https://github.com/Miskat362)
- ğŸ LinkedIn: [Connect](https://linkedin.com/in/miskat-ahmmed)

---

## âœ” Acknowledgments

- **Scikit-learn** - Machine learning library
- **FastAPI** - Modern web framework
- **MLflow** - Experiment tracking
- **DagsHub** - ML versioning and collaboration
- **MongoDB** - NoSQL database

---
#### ğŸ¤ Contributions are welcome!

---
<div align="center">

**â­ If you found this project helpful, please star it! â­**

</div>